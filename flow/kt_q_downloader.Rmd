---
title: "larimer_q_downloader"
author: "Katie Willi"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(jsonlite)
library(httr)
library(arrow)
```

###### Alternative workflow for `larimer_q_downloader`

Sites of interest:
```{r}
clp_stations <-  c("11531", "11530", "11525", "11514", "11004", "11515",
                   "11518", "11517", "11516", "6770", "11083", "11082",
                   "11009","7130","10408", "11021")

bigt_stations <- c("11567", "11566", "11564", "11563", "11562", "11561",
                   "11560", "11559", "11558", "95100", "95000", "3640",
                   "3610", "3570", "3520")
```

Getting meta-data
```{r}
meta_urler <- function(stations){
  
  # sub-test it:
  # stations <- "11567"
  
  url <- paste0("https://larimerco-ns5.trilynx-novastar.systems/novastar/data/api/v1/",
                "stationSummaries?forOperatorStationDashboard=true&stationNumId=", stations, 
                "&periodStart=2022-01-25T13:59:00-07:00&periodEnd=", Sys.Date(),
                "T13:59:00-07:00")
  
  request <- httr::GET(url = url)
  
  total_list <- httr::content(request)
  
  basics <- total_list[["stationSummaries"]][[1]] %>% 
    rbind() %>% 
    as_tibble() %>%
    dplyr::select(id, numId, name, elevation, lat = latitude, long = longitude)
  
  station_meta <- as.data.frame(do.call(rbind, 
                                        total_list[["stationSummaries"]][[1]][["dataTypes"]] )) %>%
    rename(dataType = name) %>%
    cbind(basics)
  
  Sys.sleep(1)  
  
  return(station_meta)
  
}

clp_meta <- clp_stations %>%
  map(~ meta_urler(stations = .)) %>%
  dplyr::bind_rows() %>%
  mutate(WS = "CLP")

bigt_meta <- bigt_stations %>%
  map(~ meta_urler(stations = .)) %>%
  dplyr::bind_rows() %>%
  mutate(WS = "BigT")

final_meta <- bind_rows(clp_meta, bigt_meta) %>% 
  as.data.frame() %>%
  dplyr::select(WS, description = name, id, numId, dataType, elevation, lat, long) %>%
  # i think the list structure is making things funky... so explicitly calling 
  # out what each column type is here:
  mutate(WS = as.character(WS),
         description = as.character(description),
         id = as.numeric(id),
         numId = as.numeric(numId),
         dataType = as.character(dataType),
         elevation = as.numeric(elevation),
         lat = as.numeric(lat),
         long = as.numeric(long), 
        site_desc = case_when(grepl("Fort Collins - ", description) 
                                                                  ~ gsub(replacement = "", "Fort Collins - ", x = description),
                                grepl("Greeley - ", description) 
                                                                  ~ gsub(replacement = "", "Greeley - ", x = description),
                                grepl("Loveland - ", description) 
                                                                  ~ gsub(replacement = "", "Loveland - ", x = description), 
                                grepl("Larimer - ", description) 
                                                                  ~ gsub(replacement = "", "Larimer - ", x = description), 
                             grepl("Windsor - ", description) 
                                                                  ~ gsub(replacement = "", "Windsor - ", x = description),
                             description == "Poudre River at Hewlett Gulch Bridge" ~ "Poudre River at Hewlett Gulch Bridge")) 
```

Discharge data:
```{r}
q_sites <- final_meta %>%
  filter(grepl("Discharge", dataType)) %>%
  distinct(numId) %>%
  unlist() %>%
  unname()

q_downloader <- function(q_sites){
  
  # sub-test it:
  #q_sites <- "11518"
  
  url <- paste0("https://larimerco-ns5.trilynx-novastar.systems/novastar/data/api/v1/",
                "stationSummaries?forOperatorStationDashboard=true&stationNumId=", q_sites,
                "&periodStart=2015-01-25T13:59:00-07:00&periodEnd=", Sys.Date(),
                "T13:59:00-07:00")
  
  request <- httr::GET(url = url)
  
  total_list <- httr::content(request)
  
  discharge_rows <- as_tibble(do.call(rbind, 
                                      total_list[["stationSummaries"]][[1]][["ts"]])) %>%
    rowid_to_column() %>%
    filter(grepl("Discharge",dataType)) %>%
    pull(rowid)
  
  q_unlister <- function(discharge_rows){
    
    q_meta <- total_list[["stationSummaries"]][[1]][["ts"]][[as.numeric(discharge_rows)]] %>%
      rbind() %>%
      as.data.frame() %>%
      dplyr::select(-c(data, properties))
    
    unlisted_q <- total_list[["stationSummaries"]][[1]][["ts"]][[as.numeric(discharge_rows)]][["data"]] %>%
      bind_rows() %>%
      mutate(locId = as.character(q_meta$locId)) %>%
      #left_join(q_meta, by = "locId") %>%
      as.data.frame()
  
    return(unlisted_q)
    
}
  
  flow <- discharge_rows %>%
    map(~ q_unlister(discharge_rows = .)) %>%
    dplyr::bind_rows()
  
  return(flow)
  
}

q_for_all <- q_sites %>%
  map(~ q_downloader(q_sites = .)) %>%
  list_rbind()



meta_for_join <- final_meta%>%
  filter(dataType == "DischargeRiver")%>%
  mutate(locId = as.character(numId))%>%
  distinct(locId, .keep_all = TRUE)

q_for_all_wmeta <- q_for_all%>%
  left_join(meta_for_join, by = "locId")%>%
  mutate(datetime = lubridate::ymd_hms(dt),
         q_cfs = as.numeric(v)) 
  
```

## Check the Q

I'd recommend going to https://larimerco-ns5.trilynx-novastar.systems/novastar/operator/#/stationDashboard/100
to double check and make sure the data looks similar to the sites you pulled

```{r}
test_df_q <- q_for_all_wmeta %>%
  filter( locId == "6770")%>%
  select(datetime, q_cfs, locId) %>%
  as_tibble()




#werks
ggplot(data = test_df_q) +
  geom_line(aes(x = unlist(datetime), y = q_cfs)) +
  theme_bw() 
facet_wrap(~ locId)



```

# Exporting Q to arrow
```{r}

write_feather(q_for_all_wmeta, sink = "data/Q_modeling/larimer_co_2015-01-25_2023-01-30")

```


