---
title: "cap rod intake"
format: html
editor: visual
---

## Packages

```{r setup}
require("knitr")
opts_knit$set(root.dir = "~/Repositories/cameron_peak_fire_study/")
library(tidyverse)
library(lubridate)
library(ggplot2)
library(plotly)


```

## Correcting Functions

DriftR package is not up to date with Rstudio so I am sourcing the functions from a folder called driftR_functions in the src folder

```{r}
source("src/driftR_functions/dr_correctOne.R")
source("src/driftR_functions/dr_correctTwo.R")
source("src/driftR_functions/dr_drop.R")
source("src/driftR_functions/dr_factor.R")
source("src/driftR_functions/dr_read.R")
source("src/driftR_functions/dr_readSonde.R")
source("src/driftR_functions/dr_replace.R")
source("src/driftR_functions/notInOperator.R")
source("src/driftR_functions/parseTime.R")
source("src/driftR_functions/sondeCal.R")
source("src/driftR_functions/sondeClean.R")
source("src/driftR_functions/sondeRaw.R")

```

## Importing and Combining

RULES:

1.  All data must be in CSVs nested in the folders data/all_sites/

2.  All files must have naming convention: SITE\_#DATE#

3.  All files must have same number of columns and column names

4.  All files must have the same DateTime format (can be adjusted below)

5.  Run all_data first to get what the pattern for gsub will be

    1.  This is also a good way to test that none of your files are broken

6.  Use plots to double check everything

```{r}
#function testing to create one df with all caprod data
read_and_combine <- function(folder_path, full_folder_path){
  
  # This ensures that version 2.0+ of the readr package (tidyverse) is being
  # used, because it allows for reading multiple files
  readr::local_edition(2) 
  
  # Read in all data files from all
  all_data <- read_csv(
    # Provide a vector/list of filenames to read
    file = list.files(
      path = folder_path,
      # Search in all subfolders of `path` for csv files
      recursive = TRUE,
      # Use full filenames so R can find them
      full.names = TRUE),
    # Store the path to each csv in a "path" column
    id = "path")
  
  # Now tidy up the dataset before returning it to the main workflow
  cleaned_data <- all_data %>%
    mutate(
      # Create a new column with a shortened version of the path
      site_code = gsub(pattern = full_folder_path,
                     replacement = "",
                     x = path),
      # Extract just the folder name from this shortened version of the path
      site_code = str_extract(string = site_code,
      # Remove everything after the first bit of upper case text
        pattern = "[A-Z]+"),
      
      DT =  as.POSIXct(datetime, format = "%m/%d/%Y %H:%M", tz = "MST")
    )
}

## All sites combined into 1 dataframe
# change "" to the file path were all_sites is located

stage_dataframe <- read_and_combine(folder_path = "~/Repositories/cameron_peak_fire_study/data/all_sites_caprod_data",
                                    full_folder_path = "C:/Users/Sam Struthers/OneDrive - Colostate/Documents/Repositories/cameron_peak_fire_study/data/all_sites_caprod_data/")%>%
  select(DT, site_code, wtrhgt__5)%>%
  mutate(water_height_cm = wtrhgt__5 /10, 
        time =  format(DT, format = "%H:%M"), 
        site_code = str_extract(string = site_code, 
                                      pattern = "[A-Z]+"))%>%
  dplyr ::rename(water_height_mm = wtrhgt__5)

```

## 

## Visual

-   check for missing data, weird end dates etc

```{r}
master_visual <- all_sites_combined%>%
  ggplot(aes(x= DT, y = water_height_cm, color = site_code))+
  geom_line()
plot(master_visual)

indv_visual <- filter(all_sites_combined, site_code == "FISH")%>%
  ggplot(aes(x= DT, y = water_height_cm, color = site_code))+
  geom_point()
plot(indv_visual)
```

## Export Masterfile

```{r}
write_csv(all_sites_combined, "data/all_sites_combined_UNCLEAN.csv")
```

## Remove negative values

To remove negative values and data when the sensor was being cleaned

```{r}

removed_neg <- all_sites_combined%>%
  filter(water_height_mm>=0)


removed_and_unclean <- ggplot()+
    geom_line(data = filter(all_sites_combined, site_code == "SHEP"), aes(x= DT, y= water_height_cm), color= "red")+
  geom_line(data = filter(removed_neg, site_code == "SHEP"), aes(x= DT, y= water_height_cm), color= "black")
ggplotly(removed_and_unclean)
```

## Computing daily averages

```{r}

daily_means <- read_csv("masterfiles/all_sites_caprod_masterfile_cleaned.csv")%>%
  mutate(dayofyear = yday(datetime), 
         Date = date(datetime), 
         Site = site_code)%>%
  group_by(dayofyear, Site, Date)%>%
  mutate(mean_water_height_cm = mean(water_height_cm))%>%
  ungroup()

#Match up with FCW and ISCO Samples 

site_labels <- c("FISH", "BEAV", "BENN", "SAWM", "PENN", "BLAK", "SHEP", "LBEA", "ROAR", "SAWM_ISCO", "FISH_ISCO", "LBEA_ISCO", 'BLAK_ISCO' )

cam_pk_chem <- read.csv("data/cam_pk_master_110322.csv")%>%
  filter(Era == "FCW" | Era == "ISCO")%>%
  filter(SiteLabel %in% site_labels)%>%
  mutate( grab_date  = as.Date(Date, format = "%d-%b-%y"), 
          Year = year(grab_date), 
          dayofyear = yday(grab_date))%>%
  filter(Year >=2022)%>%
  filter(SampleType %in% c("NORM", "ISCO"))%>%
  select(grab_date, SiteLabel, Era, EraSamp, dayofyear, SampleType)%>%
mutate(Site=ifelse(SiteLabel %in% c('FISH','FISH_ISCO'),"FISH",
                   ifelse(SiteLabel %in% c('LBEA','LBEA_ISCO'),"LBEA",
                   ifelse(SiteLabel %in% c('SAWM','SAWM_ISCO'),"SAWM",
                   ifelse(SiteLabel %in% c('BLAK','BLAK_ISCO'),"BLAK",SiteLabel )))))



sample_by_day <- cam_pk_chem%>%
  group_by(Site, dayofyear, SampleType)%>%
  summarise( count = n())%>%
  ungroup()






daily_means_w_samples <- daily_means%>%
  #left_join( select(cam_pk_chem, c(Site, SiteLabel, dayofyear, grab_date,SampleType, Era )), by = "dayofyear")%>%
  left_join( select(sample_by_day, c(Site, dayofyear, count,SampleType )), by = c("Site", "dayofyear") )



sample_plot <- filter(daily_means_w_samples, Site == "FISH")%>%
  ggplot()+
  geom_line(aes(x= Date, y = mean_water_height_cm, group = Site, color = Site))+
  geom_point(aes(x= Date, y = count, color = SampleType ))

plot(sample_plot)

#Write daily averages file matched up with sample #

write_csv(select(daily_means_w_samples, c(Date, mean_water_height_cm, Site, SampleType, count)), "masterfiles/daily_mean_samples_masterfile_cleaned.csv")

```

## Field data adjustments:

WORK IN PROGRESS

Trying to adjust stage data based on field measurements

-   initially tried to use driftR but that wasn't doing the adjustment I wanted

-   Got a method that I liked visually but is less reproducible than I would like

    -   Hoping to use that method in a function so that it can be worked into targets

```{r}






 

#ADJUSTING USING driftR Functions, written in Correcting Functions

#Pulling in manual values
manual_values<- read.csv("data/Manual_stage_discharge.csv")%>%
   mutate(datetime = as.POSIXct(DateTime, format = "%m/%d/%Y %H:%M", tz = "MST"),
          time =  format(DateTime, format = "%H:%M"))%>% 
    dplyr::rename(site_code = Site)

#Testing workflow with one site data

fish_manual <- read.csv("data/manual_values_dec_2022.csv")%>%
      mutate(first_measurement_DT = as.POSIXct(first_measurement_DT, format = "%m/%d/%Y %H:%M", tz = "MST"), 
             last_measurement_DT = as.POSIXct(last_measurement_DT, format = "%m/%d/%Y %H:%M", tz = "MST"))


#TRYING TO WRITE ADJUSTMENT TEST
fish_test_factor <- dr_factor(fish_adjust_test, corrFactor = corrFac, dateVar = date, timeVar = time, keepDateTime = TRUE )


dr_correctOne()


#Doing adjustment 

fish_adjusted <- dr_correctTwo(fish_test_factor, sourceVar = water_height_cm, cleanVar = height_clean_cm, calValLow = 11.8, calValHigh = 31, calStdLow = 22, calStdHigh = 20.6, factorVar = corrFac )

# waterTibble <- dr_correctTwo(waterTibble, sourceVar = pH, cleanVar = pH_corr, calValLow = 7.01,
#                            calStdLow = 7, calValHigh = 11.8, calStdHigh = 10, factorVar = corfac)







#corrected stage height <- get rid of error data, known zeros -> NA

#adjusted _stage <- adjust entire dataset by X cm based on an average of measured vs sensor
#drift_corrected stage <- apply driftR 

#map (start date, end date, measured manual height, )

#interpolated data?



  
FISH_stage_adjusted <- pmap_dfr(list(fish_manual$first_measurement_DT, 
            fish_manual$last_measurement_DT,
            fish_manual$first_measurement_cm,
            fish_manual$last_measurement_cm),
       adjust_stage, 
       stage_df= stage_dataframe,
          site_name = "FISH",
          start_date = fish_manual$first_measurement_DT, 
          end_date = fish_manual$last_measurement_DT, 
          manual_start = fish_manual$first_measurement_cm)

 #MAP IN THIS ORDER
 dr_factor()
 
 #dr_drop if correct one does like NAs
 
   
   
  dr_correctOne()
  
  
##Function to adjust stage values to match start measurement  
  
  
  adjust_stage <- function(stage_df,site_name,start_date, end_date, manual_start){
    stage_df_new<- stage_df%>%
     dplyr::filter(stage_df$site_code %in% site_name)%>%
     dplyr::filter(between(DT, start_date, end_date))%>%
      mutate(adjustment = manual_start - mean(head(water_height_cm, n = 4), na.rm = TRUE) , 
             adjusted_stage = water_height_cm + adjustment)
    
    return(stage_df_new)
    
   
  }
  
  
 fish_fun_adjustment <- adjust_stage(stage_df = stage_dataframe,
                                      site_name = "FISH",
                                      start_date = fish_manual$first_measurement_DT[4],
                                      end_date = fish_manual$last_measurement_DT[4], manual_start = fish_manual$first_measurement_cm[4])
 
  
  fish_non_adjusted_graph <- ggplot()+
  geom_line(data = fish_fun_adjustment, aes( x= DT , y= water_height_cm), color= "black")+
  geom_line(data = fish_fun_adjustment, aes( x= DT , y= adjusted_stage), color= "green", alpha = .5)+
  geom_point(data = fish_manual, aes( x= first_measurement_DT , y= first_measurement_cm), color = "blue")

plot(fish_non_adjusted_graph)
  
```
